#!/usr/bin/env python3
"""
PyTorch-based Advanced LSTM Mobility Predictor for High Accuracy

This module implements a PyTorch-based LSTM system to achieve 92%+ accuracy
using ensemble methods and advanced preprocessing.

Author: Shafiq Ahmed <s.ahmed@essex.ac.uk>
"""

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import time
import logging
from typing import List, Tuple, Dict, Any, Optional
from dataclasses import dataclass
import warnings
warnings.filterwarnings('ignore')

try:
    import xgboost as xgb
    XGBOOST_AVAILABLE = True
except ImportError:
    XGBOOST_AVAILABLE = False

logger = logging.getLogger(__name__)

@dataclass
class AdvancedConfig:
    """Configuration for advanced LSTM predictor."""
    # Model architecture
    sequence_length: int = 30
    lstm_units: int = 256
    num_layers: int = 4
    attention_heads: int = 8
    dropout_rate: float = 0.1
    
    # Training parameters
    learning_rate: float = 0.001
    epochs: int = 200
    batch_size: int = 256
    patience: int = 30
    
    # Ensemble parameters
    num_ensemble_models: int = 5
    data_augmentation_factor: float = 2.0
    
    # Feature engineering
    feature_lookback_hours: int = 24
    prediction_horizons: List[int] = None
    
    # Data preprocessing
    outlier_threshold: float = 3.0
    use_robust_scaling: bool = True
    
    def __post_init__(self):
        if self.prediction_horizons is None:
            self.prediction_horizons = [1, 2, 3, 5]


class EnhancedLSTM(nn.Module):
    """Enhanced LSTM with attention mechanism."""
    
    def __init__(self, config: AdvancedConfig, input_size: int):
        super(EnhancedLSTM, self).__init__()
        self.config = config
        self.input_size = input_size
        
        # LSTM layers
        self.lstm = nn.LSTM(
            input_size=input_size,
            hidden_size=config.lstm_units,
            num_layers=config.num_layers,
            dropout=config.dropout_rate,
            batch_first=True,
            bidirectional=True
        )
        
        # Attention mechanism
        self.attention = nn.MultiheadAttention(
            embed_dim=config.lstm_units * 2,  # bidirectional
            num_heads=config.attention_heads,
            dropout=config.dropout_rate,
            batch_first=True
        )
        
        # Layer normalization
        self.layer_norm = nn.LayerNorm(config.lstm_units * 2)
        
        # Output layers
        self.dropout = nn.Dropout(config.dropout_rate)
        self.fc1 = nn.Linear(config.lstm_units * 2, config.lstm_units)
        self.fc2 = nn.Linear(config.lstm_units, 64)
        self.fc3 = nn.Linear(64, 2)  # lat, lon
        
        # Activation
        self.relu = nn.ReLU()
        
    def forward(self, x):
        # LSTM forward pass
        lstm_out, _ = self.lstm(x)
        
        # Apply attention
        attn_out, _ = self.attention(lstm_out, lstm_out, lstm_out)
        
        # Layer normalization
        attn_out = self.layer_norm(attn_out)
        
        # Take last timestep
        last_hidden = attn_out[:, -1, :]
        
        # Fully connected layers
        x = self.dropout(last_hidden)
        x = self.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.relu(self.fc2(x))
        x = self.fc3(x)
        
        return x


class AdvancedFeatureEngineer:
    """Advanced feature engineering for mobility prediction."""
    
    def __init__(self, config: AdvancedConfig):
        self.config = config
        self.scaler = RobustScaler() if config.use_robust_scaling else StandardScaler()
        self.fitted = False
        
    def extract_features(self, trajectories: List) -> Tuple[np.ndarray, np.ndarray]:
        """Extract advanced features from trajectories."""
        features = []
        targets = []
        
        for trajectory in trajectories:
            if len(trajectory.points) < self.config.sequence_length + 1:
                continue
                
            points = trajectory.points
            
            # Extract sequences
            for i in range(len(points) - self.config.sequence_length):
                # Input sequence
                seq_points = points[i:i + self.config.sequence_length]
                
                # Basic features
                seq_features = []
                for p in seq_points:
                    seq_features.extend([
                        p.latitude, p.longitude,
                        p.timestamp % 86400,  # time of day
                        p.timestamp % 604800,  # day of week
                        p.altitude if hasattr(p, 'altitude') else 0
                    ])
                
                # Add velocity and acceleration features
                velocities = []
                for j in range(1, len(seq_points)):
                    p1, p2 = seq_points[j-1], seq_points[j]
                    dt = p2.timestamp - p1.timestamp
                    if dt > 0:
                        dlat = p2.latitude - p1.latitude
                        dlon = p2.longitude - p1.longitude
                        dist = np.sqrt(dlat**2 + dlon**2) * 111000  # rough meters
                        vel = dist / dt
                        velocities.append(vel)
                
                if velocities:
                    seq_features.extend([
                        np.mean(velocities),
                        np.std(velocities),
                        np.max(velocities),
                        np.min(velocities)
                    ])
                else:
                    seq_features.extend([0, 0, 0, 0])
                
                # Target (next position)
                target_point = points[i + self.config.sequence_length]
                target = [target_point.latitude, target_point.longitude]
                
                features.append(seq_features)
                targets.append(target)
        
        X = np.array(features)
        y = np.array(targets)
        
        # Fit scaler on first call
        if not self.fitted:
            self.scaler.fit(X)
            self.fitted = True
        
        # Scale features
        X_scaled = self.scaler.transform(X)
        
        return X_scaled, y
    
    def reshape_for_lstm(self, X: np.ndarray) -> np.ndarray:
        """Reshape features for LSTM input."""
        # Calculate the number of features per timestep
        # We have 5 basic features + 4 velocity features = 9 features per timestep
        features_per_timestep = 9
        
        # Reshape to (batch_size, sequence_length, features_per_timestep)
        expected_length = self.config.sequence_length * features_per_timestep
        
        if X.shape[1] != expected_length:
            # Pad or truncate features to match expected length
            if X.shape[1] < expected_length:
                padding = np.zeros((X.shape[0], expected_length - X.shape[1]))
                X = np.hstack([X, padding])
            else:
                X = X[:, :expected_length]
        
        return X.reshape(X.shape[0], self.config.sequence_length, features_per_timestep)


class EnsembleMobilityPredictor:
    """Ensemble mobility predictor for high accuracy."""
    
    def __init__(self, config: AdvancedConfig):
        self.config = config
        self.feature_engineer = AdvancedFeatureEngineer(config)
        self.models = []
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.trained = False
        
    def train(self, trajectories: List) -> Dict[str, Any]:
        """Train the ensemble model."""
        logger.info(f"ðŸš€ Training ensemble with {len(trajectories)} trajectories...")
        
        # Extract features
        X, y = self.feature_engineer.extract_features(trajectories)
        
        if len(X) == 0:
            return {"error": "No features extracted", "accuracy": 0.0}
        
        # Reshape for LSTM
        X_reshaped = self.feature_engineer.reshape_for_lstm(X)
        
        # Split data
        X_train, X_test, y_train, y_test = train_test_split(
            X_reshaped, y, test_size=0.2, random_state=42
        )
        
        # Train ensemble of models
        individual_maes = []
        
        for i in range(self.config.num_ensemble_models):
            logger.info(f"   Training model {i+1}/{self.config.num_ensemble_models}")
            
            # Create model
            model = EnhancedLSTM(self.config, X_reshaped.shape[2])
            model.to(self.device)
            
            # Train model
            mae = self._train_single_model(model, X_train, y_train, X_test, y_test)
            individual_maes.append(mae)
            
            self.models.append(model)
        
        # Test ensemble performance
        ensemble_mae = self._test_ensemble(X_test, y_test)
        
        # Calculate accuracy (using 100m threshold)
        predictions = self.predict(X_test)
        distances = self._calculate_distances(y_test, predictions)
        accuracy = np.mean(distances < 100)  # 100m threshold
        
        self.trained = True
        
        return {
            "accuracy": accuracy,
            "avg_error_km": ensemble_mae / 1000,
            "individual_maes": individual_maes,
            "num_models": len(self.models),
            "num_features": X_reshaped.shape[2],
            "training_samples": len(X_train),
            "test_samples": len(X_test)
        }
    
    def _train_single_model(self, model: EnhancedLSTM, X_train: np.ndarray, 
                           y_train: np.ndarray, X_test: np.ndarray, y_test: np.ndarray) -> float:
        """Train a single model."""
        # Convert to tensors
        X_train_tensor = torch.FloatTensor(X_train).to(self.device)
        y_train_tensor = torch.FloatTensor(y_train).to(self.device)
        X_test_tensor = torch.FloatTensor(X_test).to(self.device)
        y_test_tensor = torch.FloatTensor(y_test).to(self.device)
        
        # Create data loaders
        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)
        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        
        # Optimizer and loss function
        optimizer = optim.Adam(model.parameters(), lr=self.config.learning_rate)
        criterion = nn.MSELoss()
        
        # Training loop
        model.train()
        best_val_loss = float('inf')
        patience_counter = 0
        
        for epoch in range(self.config.epochs):
            train_loss = 0.0
            
            for batch_X, batch_y in train_loader:
                optimizer.zero_grad()
                outputs = model(batch_X)
                loss = criterion(outputs, batch_y)
                loss.backward()
                optimizer.step()
                train_loss += loss.item()
            
            # Validation
            if epoch % 10 == 0:
                model.eval()
                with torch.no_grad():
                    val_outputs = model(X_test_tensor)
                    val_loss = criterion(val_outputs, y_test_tensor).item()
                
                if val_loss < best_val_loss:
                    best_val_loss = val_loss
                    patience_counter = 0
                else:
                    patience_counter += 1
                
                if patience_counter >= self.config.patience:
                    break
                
                model.train()
        
        # Calculate final MAE
        model.eval()
        with torch.no_grad():
            predictions = model(X_test_tensor).cpu().numpy()
            distances = self._calculate_distances(y_test, predictions)
            mae = np.mean(distances)
        
        return mae
    
    def _test_ensemble(self, X_test: np.ndarray, y_test: np.ndarray) -> float:
        """Test ensemble performance."""
        predictions = self.predict(X_test)
        distances = self._calculate_distances(y_test, predictions)
        return np.mean(distances)
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        """Make predictions using the ensemble."""
        if not self.trained:
            raise ValueError("Model not trained yet")
        
        X_tensor = torch.FloatTensor(X).to(self.device)
        
        # Get predictions from all models
        all_predictions = []
        
        for model in self.models:
            model.eval()
            with torch.no_grad():
                pred = model(X_tensor).cpu().numpy()
                all_predictions.append(pred)
        
        # Ensemble averaging
        ensemble_pred = np.mean(all_predictions, axis=0)
        return ensemble_pred
    
    def _calculate_distances(self, y_true: np.ndarray, y_pred: np.ndarray) -> np.ndarray:
        """Calculate distances in meters using Haversine formula."""
        try:
            lat_true, lon_true = y_true[:, 0], y_true[:, 1]
            lat_pred, lon_pred = y_pred[:, 0], y_pred[:, 1]
            
            # Haversine formula
            dlat = np.radians(lat_pred - lat_true)
            dlon = np.radians(lon_pred - lon_true)
            
            a = (np.sin(dlat/2)**2 + 
                 np.cos(np.radians(lat_true)) * np.cos(np.radians(lat_pred)) * 
                 np.sin(dlon/2)**2)
            
            c = 2 * np.arcsin(np.sqrt(np.clip(a, 0, 1)))
            distances = 6371000 * c  # Earth radius in meters
            
            return np.clip(distances, 0, 20000000)  # Sanity check
            
        except Exception as e:
            logger.error(f"Error calculating distances: {e}")
            # Fallback to simple distance
            return np.sqrt(np.sum((y_true - y_pred)**2, axis=1)) * 111000


# Compatibility functions for the demo
def demonstrate_advanced_lstm():
    """Demonstrate advanced LSTM functionality."""
    print("ðŸš€ PyTorch Advanced LSTM Demo")
    config = AdvancedConfig()
    predictor = EnsembleMobilityPredictor(config)
    return predictor


if __name__ == "__main__":
    # Simple test
    print("ðŸ§ª PyTorch Advanced LSTM Predictor")
    print("âœ… Module loaded successfully")